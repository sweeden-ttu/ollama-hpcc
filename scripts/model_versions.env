#!/usr/bin/env bash
# =============================================================================
# model_versions.env
# Central configuration for OLLAMA model names and versions on RedRaider HPCC
# Source this file in all scripts: source "$(dirname "$0")/model_versions.env"
# =============================================================================
#
# Versions chosen: latest <10B parameter models available on ollama.com
# as of 2026-02-26
#
# granite    → granite4:3b           (IBM Granite 4 "micro", 3B params, ~2.1GB)
#                                     granite4 also has :1b (3.3GB, 128K ctx) and
#                                     hybrid Mamba-2 variants with -h suffix
#                                     granite3.3:8b is the previous generation
# deepseek   → deepseek-r1:8b        (DeepSeek-R1-0528-Qwen3, 8B params, ~5.2GB)
# qwen-coder → qwen2.5-coder:7b      (Qwen 2.5 Coder, 7B params, ~4.7GB)
# codellama  → codellama:7b          (Meta CodeLlama, 7B params, ~3.8GB)

export GRANITE_MODEL="granite4"
export GRANITE_VERSION="3b"

export DEEPSEEK_MODEL="deepseek-r1"
export DEEPSEEK_VERSION="8b"

export QWENCODER_MODEL="qwen2.5-coder"
export QWENCODER_VERSION="7b"

export CODELLAMA_MODEL="codellama"
export CODELLAMA_VERSION="7b"

# HPCC / SLURM settings
export OLLAMA_BIN="${HOME}/ollama-latest/bin/ollama"
export OLLAMA_LOG_DIR="${HOME}/ollama-logs"
export HPCC_PARTITION="matador"
export HPCC_GPU_COUNT=1
export HPCC_CPUS_PER_TASK=8
export HPCC_MEM_PER_CPU="4096MB"
export HPCC_TIME="08:00:00"

# Startup wait time (seconds) for ollama serve to be ready
export OLLAMA_STARTUP_WAIT=10
